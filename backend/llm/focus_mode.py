# backend/llm/focus_mode.py
import httpx 
import requests
import markdown
import json
from backend.config import (
    DEEPSEEK_API_KEY, 
    DEEPSEEK_API_URL, 
    DEEPSEEK_REASONER_MODEL,
    NAHIDA_PROMPT
)

def get_nahida_response(user_input: str) -> dict:
    """
    çº³è¥¿å¦²ä¸“å±å¤„ç†å‡½æ•° (æ— çŠ¶æ€ + æ·±åº¦æ€è€ƒ)
    """
    # 1. æ„é€ è¯·æ±‚å¤´
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
    }
    
    # 2. æ„é€ æ¶ˆæ¯
    # æ³¨æ„ï¼šè¿™é‡Œä¸ä¼ å…¥ _chat_historyï¼Œçº³è¥¿å¦²æ¯æ¬¡éƒ½åŸºäºå…¨æ–°çš„è§†è§’æ€è€ƒ
    messages = [
        {"role": "system", "content": NAHIDA_PROMPT},
        {"role": "user", "content": user_input}
    ]
    
    # 3. æ„é€  Payloadï¼Œåˆ‡æ¢åˆ°æ¨ç†æ¨¡å‹
    payload = {
        "model": DEEPSEEK_REASONER_MODEL,
        "messages": messages,
        "stream": False, 
        "max_tokens": 4096, # æ·±åº¦æ€è€ƒéœ€è¦æ›´å¤šå­—æ•°
        "temperature": 0.8  # ç¨å¾®æœ‰ä¸€ç‚¹ç‚¹çµåŠ¨
    }
    
    try:
        print(f"ğŸŒ± [çº³è¥¿å¦²] æ­£åœ¨é“¾æ¥è™šç©ºç»ˆç«¯è¿›è¡Œæ€è€ƒ... (Model: {DEEPSEEK_REASONER_MODEL})")
        response = requests.post(DEEPSEEK_API_URL, headers=headers, json=payload, timeout=90) # æ¨ç†æ¨¡å‹è¾ƒæ…¢ï¼Œè¶…æ—¶è®¾é•¿ç‚¹
        
        # è°ƒè¯•ï¼šæ‰“å°ä¸€ä¸‹çœ‹çœ‹æ˜¯å¦å‡ºé”™
        if response.status_code != 200:
            print(f"API Error: {response.text}")
            
        response.raise_for_status()
        data = response.json()
        
        if "choices" in data and len(data["choices"]) > 0:
            message_obj = data["choices"][0]["message"]
            
            # 4. å…³é”®ç‚¹ï¼šæå–æ€ç»´é“¾ (Reasoning Content)
            # DeepSeek R1 ä¼šæŠŠæ€è€ƒè¿‡ç¨‹æ”¾åœ¨ reasoning_content å­—æ®µï¼ŒæŠŠç»“æœæ”¾åœ¨ content å­—æ®µ
            reasoning_text = message_obj.get("reasoning_content", "")
            final_content = message_obj.get("content", "")
            
            # å¦‚æœç”¨çš„æ˜¯æ™®é€šæ¨¡å‹å…¼å®¹ï¼Œreasoning_text å¯èƒ½ä¸ºç©ºï¼Œæˆ‘ä»¬åšä¸ªå¤„ç†
            if not reasoning_text:
                reasoning_text = "ï¼ˆçº³è¥¿å¦²æ­£åœ¨æ•´ç†è™šç©ºä¸­çš„çŸ¥è¯†...ï¼‰"
            
            # 5. æ ¼å¼åŒ–ä¸ºå‰ç«¯å¯å±•ç¤ºçš„ HTML
            html_output = _format_nahida_html(reasoning_text, final_content)
            
            return {
                "raw": final_content,
                "html": html_output,
                "mode": "focus"
            }
        else:
            raise ValueError("APIå“åº”æ ¼å¼å¼‚å¸¸")

    except Exception as e:
        error_msg = f"å“å‘€ï¼Œè™šç©ºç»ˆç«¯è¿æ¥å¥½åƒæ–­å¼€äº†... ({str(e)})"
        return {
            "raw": error_msg,
            "html": f'<div class="error-message">{error_msg}</div>',
            "mode": "focus"
        }

async def stream_nahida_response(user_input: str):
    """
    çº³è¥¿å¦²æ·±åº¦æ€è€ƒæ¨¡å¼çš„æµå¼ç”Ÿæˆå™¨
    """
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
    }
    
    messages = [
        {"role": "system", "content": NAHIDA_PROMPT},
        {"role": "user", "content": user_input}
    ]
    
    payload = {
        "model": DEEPSEEK_REASONER_MODEL,
        "messages": messages,
        "stream": True,  # å¿…é¡»å¼€å¯æµå¼
        "max_tokens": 4096,
        "temperature": 0.6
    }
    
    try:
        # å¢åŠ è¶…æ—¶æ—¶é—´ï¼ŒDeepSeek R1 æ€è€ƒæ—¶é—´å¯èƒ½è¾ƒé•¿
        timeout = httpx.Timeout(connect=10.0, read=120.0, write=10.0, pool=10.0)
        
        async with httpx.AsyncClient(timeout=timeout) as client:
            async with client.stream("POST", DEEPSEEK_API_URL, headers=headers, json=payload) as response:
                
                if response.status_code != 200:
                    error_msg = f"API Error: {response.status_code} - {response.reason_phrase}"
                    # å‘é€é”™è¯¯äº‹ä»¶ç»™å‰ç«¯
                    yield f"data: {json.dumps({'type': 'error', 'content': error_msg}, ensure_ascii=False)}\n\n"
                    return

                # ä½¿ç”¨ aiter_lines() é€è¡Œè¯»å–ï¼Œå¹¶å¤„ç†å¯èƒ½çš„ç©ºè¡Œ
                async for line in response.aiter_lines():
                    line = line.strip() # å»é™¤é¦–å°¾ç©ºç™½
                    
                    if not line:
                        continue # è·³è¿‡ç©ºè¡Œï¼ˆå¿ƒè·³åŒ…ï¼‰
                        
                    if line.startswith("data: "):
                        json_str = line[6:]  # å»æ‰ 'data: ' å‰ç¼€
                        
                        # æ£€æŸ¥ç»“æŸæ ‡è®°
                        if json_str.strip() == "[DONE]":
                            break
                        
                        try:
                            chunk = json.loads(json_str)
                            if "choices" not in chunk or len(chunk["choices"]) == 0:
                                continue
                                
                            delta = chunk["choices"][0]["delta"]
                            
                            # A. æ•æ‰æ€è€ƒè¿‡ç¨‹ (Reasoning Content)
                            if "reasoning_content" in delta and delta["reasoning_content"]:
                                packet = {
                                    "type": "thinking", 
                                    "content": delta["reasoning_content"]
                                }
                                yield f"data: {json.dumps(packet, ensure_ascii=False)}\n\n"
                            
                            # B. æ•æ‰æœ€ç»ˆå›ç­” (Content)
                            elif "content" in delta and delta["content"]:
                                packet = {
                                    "type": "answer", 
                                    "content": delta["content"]
                                }
                                yield f"data: {json.dumps(packet, ensure_ascii=False)}\n\n"
                                
                        except json.JSONDecodeError:
                            print(f"âš ï¸ JSONè§£æå¤±è´¥: {line}")
                            continue
                            
    except Exception as e:
        import traceback
        traceback.print_exc() # æ‰“å°åç«¯æŠ¥é”™è¯¦æƒ…
        yield f"data: {json.dumps({'type': 'error', 'content': str(e)}, ensure_ascii=False)}\n\n"

def _format_nahida_html(reasoning: str, content: str) -> str:
    """
    å°†çº³è¥¿å¦²çš„æ€è€ƒè¿‡ç¨‹å’Œå›ç­”åŒ…è£…æˆæ¼‚äº®çš„ HTML
    """
    # å°† Markdown è½¬æ¢ä¸º HTML
    content_html = markdown.markdown(content, extensions=['fenced_code', 'tables', 'nl2br'])
    reasoning_html = markdown.markdown(reasoning, extensions=['fenced_code', 'nl2br'])
    
    html = f"""
    <div class="nahida-container">
        <!-- æ€è€ƒè¿‡ç¨‹ (é»˜è®¤å±•å¼€) -->
        <div class="thinking-box">
            <details open>
                <summary>ğŸƒ çº³è¥¿å¦²çš„æ²‰æ€ (DeepSeekæ·±åº¦æ€è€ƒ)</summary>
                <div class="thinking-content">
                    {reasoning_html}
                </div>
            </details>
        </div>
        
        <!-- æœ€ç»ˆå›ç­” -->
        <div class="nahida-answer">
            <div class="nahida-badge">å°å‰ç¥¥è‰ç‹çš„è§£ç­”</div>
            <div class="markdown-content">{content_html}</div>
        </div>
    </div>
    """
    return html